{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# âœ… Step 1: Install all necessary dependencies (fixed for LangChain v0.1+)\n",
        "!pip install -q langchain langchain-community faiss-cpu sentence-transformers transformers\n",
        "\n",
        "# âœ… Step 2: Offline dummy dataset (no download required)\n",
        "documents = [\n",
        "    \"The sun is the star at the center of the Solar System. It is a nearly perfect sphere of hot plasma, heated by nuclear fusion reactions.\",\n",
        "    \"The water cycle describes how water evaporates from the surface of the earth, rises into the atmosphere, cools and condenses into rain or snow.\",\n",
        "    \"Mahatma Gandhi was an Indian lawyer, anti-colonial nationalist and political ethicist who led the successful campaign for India's independence from British rule.\",\n",
        "    \"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods from carbon dioxide and water.\",\n",
        "    \"A black hole is a region of spacetime where gravity is so strong that nothingâ€”no particles or even electromagnetic radiation such as lightâ€”can escape from it.\",\n",
        "    \"The French Revolution was a period of far-reaching social and political upheaval in France and its colonies that lasted from 1789 until 1799.\",\n",
        "    \"Neurons are the fundamental units of the brain and nervous system, the cells responsible for receiving sensory input and sending motor commands.\",\n",
        "    \"The Constitution of India is the supreme law of India. It lays down the framework demarcating fundamental political code, structure, and powers.\",\n",
        "    \"Machine learning is a method of data analysis that automates analytical model building. It is a branch of artificial intelligence based on the idea that systems can learn from data.\",\n",
        "    \"Einstein's theory of relativity explains how space and time are linked for objects that are moving at a consistent speed in a straight line.\"\n",
        "]\n",
        "\n",
        "# âœ… Step 3: Chunk and embed the dataset\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.create_documents(documents)\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "db = FAISS.from_documents(docs, embedding_model)\n",
        "\n",
        "# âœ… Step 4: Set up the QA model and RAG chain (no API keys!)\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", max_length=256)\n",
        "llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
        "\n",
        "rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=db.as_retriever())\n",
        "\n",
        "# âœ… Step 5: Simple command-line chatbot interface\n",
        "def chat():\n",
        "    print(\"ðŸ¤– adam is ready. Ask anything! (type 'exit' to quit)\\n\")\n",
        "    while True:\n",
        "        q = input(\"You: \")\n",
        "        if q.lower() in [\"exit\", \"quit\"]:\n",
        "            print(\"adam: Goodbye ðŸ‘‹\")\n",
        "            break\n",
        "        a = rag_chain.run(q)\n",
        "        print(\"adam:\", a)\n",
        "\n",
        "# âœ… Step 6: Generate and save sample questions and responses\n",
        "import pandas as pd\n",
        "qa_pairs = [\n",
        "    \"What is photosynthesis?\",\n",
        "    \"Who was Mahatma Gandhi?\",\n",
        "    \"What is the water cycle?\",\n",
        "    \"Define a black hole.\",\n",
        "    \"Explain Einstein's theory of relativity.\",\n",
        "]\n",
        "\n",
        "output = [(q, rag_chain.run(q)) for q in qa_pairs]\n",
        "df = pd.DataFrame(output, columns=[\"Question\", \"Answer\"])\n",
        "df.to_excel(\"sample_responses.xlsx\", index=False)\n",
        "\n",
        "print(\"âœ… Setup complete! Use chat() to begin chatting, or check sample_responses.xlsx for example output.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJVGL3phkN3q",
        "outputId": "1fa5fed6-cd5b-4167-ac1a-fa38986e73a9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-4480cd43b781>:27: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n",
            "<ipython-input-1-4480cd43b781>:36: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
            "  llm = HuggingFacePipeline(pipeline=qa_pipeline)\n",
            "<ipython-input-1-4480cd43b781>:61: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  output = [(q, rag_chain.run(q)) for q in qa_pairs]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Setup complete! Use chat() to begin chatting, or check sample_responses.xlsx for example output.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uYtv5r3IleSm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}